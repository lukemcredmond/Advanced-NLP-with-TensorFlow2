{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "#from tf.keras.models import Sequential\n",
    "#from tf.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Init GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "######## GPU CONFIGS FOR RTX 2070 ###############\n",
    "## Please ignore if not training on GPU       ##\n",
    "## this is important for running CuDNN on GPU ##\n",
    "\n",
    "tf.keras.backend.clear_session() #- for easy reset of notebook state\n",
    "\n",
    "# chck if GPU can be seen by TF\n",
    "tf.config.list_physical_devices('GPU')\n",
    "# only if you want to see how commands are executed\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  print(gpus[0])\n",
    "  try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json: 142kB [00:00, 4.30MB/s]                    \n",
      "2022-03-10 20:48:21 INFO: Downloading default packages for language: en (English)...\n",
      "2022-03-10 20:48:23 INFO: File exists: C:\\Users\\lukem\\stanza_resources\\en\\default.zip.\n",
      "2022-03-10 20:48:28 INFO: Finished downloading models and saved to C:\\Users\\lukem\\stanza_resources.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import torch\n",
    "import stanza\n",
    "import pandas as pd \n",
    "import re\n",
    "import os.path\n",
    "import stopwordsiso as stopwords\n",
    "\n",
    "\n",
    "from os import path\n",
    "\n",
    "\n",
    "en = stanza.download('en') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Download Data\n",
    "\n",
    "Download the file\n",
    "Save into a temp location\n",
    "\n",
    "Unzip does not work in a windows enviroment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if not (path.exists(\"../data/spam/smsspamcollection.zip\")):\n",
    "    path_to_zip = tf.keras.utils.get_file(\"F:\\\\Users\\\\Luke\\\\Documents\\\\Git\\\\NPL\\\\Advanced-NLP-with-TensorFlow2\\\\data\\\\Spam\\\\smsspamcollection.zip\",\n",
    "                  origin=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\",\n",
    "                  extract=True)\n",
    "\n",
    "    !unzip $path_to_zip -d data\n",
    "\n",
    "lines = io.open('../data/spam/SMSSpamCollection').read().strip().split('\\n')\n",
    "lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')\n",
      "Spam:  747\n"
     ]
    }
   ],
   "source": [
    "spam_dataset = []\n",
    "count = 0\n",
    "for line in lines:\n",
    "  label, text = line.split('\\t')\n",
    "  if label.lower().strip() == 'spam':\n",
    "    spam_dataset.append((1, text.strip()))\n",
    "    count += 1\n",
    "  else:\n",
    "    spam_dataset.append(((0, text.strip())))\n",
    "\n",
    "print(spam_dataset[0])\n",
    "print(\"Spam: \", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "en = stanza.Pipeline(lang='en')\n",
    "en_sw = stopwords.stopwords('en')\n",
    "df = pd.DataFrame(spam_dataset, columns=['Spam', 'Message'])\n",
    "#train=df.sample(frac=0.8,random_state=42) #random state is a seed value\n",
    "#test=df.drop(train.index)\n",
    "\n",
    "# Normalization functions\n",
    "\n",
    "#def message_length(x):\n",
    "#  # returns total number of characters\n",
    "#  return len(x)\n",
    "\n",
    "#def num_capitals(x):\n",
    "#  _, count = re.subn(r'[A-Z]', '', x) # only works in english\n",
    "#  return count\n",
    "\n",
    "#def num_punctuation(x):\n",
    "#  _, count = re.subn(r'\\W', '', x)\n",
    "#  return count\n",
    "\n",
    "#def word_counts(x, pipeline=en):\n",
    "#  doc = pipeline(x)\n",
    "#  count = sum( [ len(sentence.tokens) for sentence in doc.sentences] )\n",
    "#  return count\n",
    "\n",
    "#def word_counts_clean(x, pipeline=en):\n",
    "#  doc = pipeline(x)\n",
    "#  count = 0\n",
    "#  for sentence in doc.sentences:\n",
    "#    for token in sentence.tokens:\n",
    "#        if token.text.lower() not in en_sw:\n",
    "#          count += 1\n",
    "#  return count\n",
    "\n",
    "#df['Capitals'] = df['Message'].apply(num_capitals)\n",
    "#df['Punctuation'] = df['Message'].apply(num_punctuation)\n",
    "#df['Length'] = df['Message'].apply(message_length)\n",
    "#df['Words'] = df['Message'].apply(word_counts)\n",
    "#df['CleanWords'] = df['Message'].apply(word_counts_clean)\n",
    "\n",
    "def normaliseData(x, pipeline=en):\n",
    "  try:\n",
    "    print(\"\\rprocessing line: \"+x)\n",
    "    doc = pipeline(x)\n",
    "    length = len(x)\n",
    "    _, capCount = re.subn(r'[A-Z]', '', x)\n",
    "    _, punctuationCount = re.subn(r'\\W', '', x)\n",
    "  \n",
    "    wordCount = sum( [ len(sentence.tokens) for sentence in doc.sentences] )\n",
    "    totals = 0.\n",
    "    count = 0.\n",
    "    non_word = 0.\n",
    "    for sentence in doc.sentences:\n",
    "      totals += len(sentence.tokens)  # (1)\n",
    "      for token in sentence.tokens:\n",
    "          if token.text.lower() not in en_sw:\n",
    "            if token.words[0].upos not in ['PUNCT', 'SYM']:\n",
    "              count += 1.\n",
    "            else:\n",
    "              non_word += 1.\n",
    "    non_word = non_word / totals\n",
    "  except:\n",
    "    capCount = -1\n",
    "    punctuationCount = -1\n",
    "    length = -1\n",
    "    wordCount = -1\n",
    "    count = -1\n",
    "    non_word = -1\n",
    "    print(\"Error processing line: \"+x)\n",
    "  finally:\n",
    "    return pd.Series([capCount,punctuationCount,length,wordCount,count, non_word], \n",
    "    index=['Capitals','Punctuation','Length','Words','Words_NoPunct', 'Punct'])\n",
    "\n",
    "\n",
    "if not (path.exists(\"../data/spam/model\")):\n",
    "  tmp_df = df['Message'].apply(normaliseData)\n",
    "  df = pd.concat([df, tmp_df], axis=1)\n",
    "  df.to_pickle(\"../data/spam/normaliseData.pkl\")\n",
    "else:\n",
    "  df = pd.read_pickle(\"../data/spam/normaliseData.pkl\")\n",
    "\n",
    "train=df.sample(frac=0.8,random_state=42) #random state is a seed value\n",
    "test=df.drop(train.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Capitals</th>\n",
       "      <th>Punctuation</th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Words_NoPunct</th>\n",
       "      <th>Punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.132765</td>\n",
       "      <td>5.405248</td>\n",
       "      <td>18.737385</td>\n",
       "      <td>79.694550</td>\n",
       "      <td>18.533752</td>\n",
       "      <td>6.381924</td>\n",
       "      <td>0.142315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.339359</td>\n",
       "      <td>11.332793</td>\n",
       "      <td>14.641426</td>\n",
       "      <td>59.476952</td>\n",
       "      <td>13.680827</td>\n",
       "      <td>5.617551</td>\n",
       "      <td>0.124327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>910.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Spam     Capitals  Punctuation       Length        Words  \\\n",
       "count  4459.000000  4459.000000  4459.000000  4459.000000  4459.000000   \n",
       "mean      0.132765     5.405248    18.737385    79.694550    18.533752   \n",
       "std       0.339359    11.332793    14.641426    59.476952    13.680827   \n",
       "min       0.000000    -1.000000    -1.000000    -1.000000    -1.000000   \n",
       "25%       0.000000     1.000000     8.000000    35.000000     9.000000   \n",
       "50%       0.000000     2.000000    14.000000    61.000000    15.000000   \n",
       "75%       0.000000     4.000000    27.000000   121.000000    27.000000   \n",
       "max       1.000000   129.000000   253.000000   910.000000   209.000000   \n",
       "\n",
       "       Words_NoPunct        Punct  \n",
       "count    4459.000000  4459.000000  \n",
       "mean        6.381924     0.142315  \n",
       "std         5.617551     0.124327  \n",
       "min        -1.000000    -1.000000  \n",
       "25%         2.000000     0.090909  \n",
       "50%         4.000000     0.142857  \n",
       "75%         9.000000     0.200000  \n",
       "max        54.000000     0.666667  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic 1-layer neural network model for evaluation\n",
    "def make_model(input_dims=3, num_units=12):\n",
    "  model = tf.keras.Sequential()\n",
    "\n",
    "  # Adds a densely-connected layer with 12 units to the model:\n",
    "  model.add(tf.keras.layers.Dense(num_units, \n",
    "                                  input_dim=input_dims, \n",
    "                                  activation='relu'))\n",
    "\n",
    "  # Add a sigmoid layer with a binary output unit:\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "446/446 [==============================] - 5s 9ms/step - loss: 4.2601 - accuracy: 0.6892\n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 4s 9ms/step - loss: 0.4369 - accuracy: 0.8784\n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 4s 8ms/step - loss: 0.2504 - accuracy: 0.9282\n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 4s 8ms/step - loss: 0.2025 - accuracy: 0.9401\n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 4s 9ms/step - loss: 0.1820 - accuracy: 0.9446\n",
      "Epoch 6/10\n",
      "446/446 [==============================] - 4s 9ms/step - loss: 0.1801 - accuracy: 0.9424\n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 4s 9ms/step - loss: 0.1740 - accuracy: 0.9433\n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 4s 9ms/step - loss: 0.1737 - accuracy: 0.9419\n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 4s 8ms/step - loss: 0.1670 - accuracy: 0.9426\n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 4s 8ms/step - loss: 0.1697 - accuracy: 0.9453\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.1918 - accuracy: 0.9417\n",
      "INFO:tensorflow:Assets written to: ../data/spam/model\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#train['Words'] = train['Message'].apply(word_counts)\n",
    "#test['Words'] = test['Message'].apply(word_counts)\n",
    "x_train = train[['Capitals','Punctuation','Length','Words','Words_NoPunct', 'Punct']]\n",
    "y_train = train[['Spam']]\n",
    "\n",
    "x_test = test[['Capitals','Punctuation','Length','Words','Words_NoPunct', 'Punct']]\n",
    "y_test = test[['Spam']]\n",
    "\n",
    "\n",
    "if not (path.exists(\"../data/spam/model\")):\n",
    "    model = make_model(input_dims=6)\n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=10)\n",
    "    model.evaluate(x_test, y_test)\n",
    "    model.save('../data/spam/model')\n",
    "else:\n",
    "    model = tf.keras.models.load_model('../data/spam/model')\n",
    "\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Closer to on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing line: Sunshine Quiz Wkly Q! Win a top Sony DVD player if u know which country the Algarve is in? Txt ansr to 82277. £1.50 SP:Tyrone\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7698292"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checkIfMsgIsSpam(msg):\n",
    "    sample = pd.DataFrame([msg], columns=['Message'])\n",
    "    tmp_sample = sample['Message'].apply(normaliseData)\n",
    "    #tmp_sample.head()\n",
    "    sample = pd.concat([sample, tmp_sample], axis=1)\n",
    "    sample_pred = model.predict(sample[['Capitals','Punctuation','Length','Words','Words_NoPunct', 'Punct']])\n",
    "    return sample_pred\n",
    "\n",
    "\n",
    "sample_pred = checkIfMsgIsSpam(\"Sunshine Quiz Wkly Q! Win a top Sony DVD player if u know which country the Algarve is in? Txt ansr to 82277. £1.50 SP:Tyrone\")\n",
    "\n",
    "sample_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "t = np.squeeze(y_test_pred).round() #.tolist()\n",
    "\n",
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['Spam'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test['Spam'].values.tolist(), t)\n",
    "plot_confusion_matrix(cm, classes=['Ham', 'Spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00252632],\n",
       "       [0.01168844],\n",
       "       [0.03557014],\n",
       "       ...,\n",
       "       [0.17161897],\n",
       "       [0.01739425],\n",
       "       [0.01193297]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tokenization and Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StanfordNLP has become https://github.com/stanfordnlp/stanza/\n",
    "#!pip install stanza  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = 'Go until jurong point, crazy.. Available only in bugis n great world'\n",
    "#sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized = en(sentence)\n",
    "#len(tokenized.sentences)\n",
    "\n",
    "\n",
    "#for snt in tokenized.sentences:\n",
    "#  for word in snt.tokens:\n",
    "#    print(word.text)\n",
    "#  print(\"<End of Sentence>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train['Words'] = train['Message'].apply(word_counts)\n",
    "#test['Words'] = test['Message'].apply(word_counts)\n",
    "#x_train = train[['Length', 'Punctuation', 'Capitals', 'Words']]\n",
    "#y_train = train[['Spam']]\n",
    "\n",
    "#x_test = test[['Length', 'Punctuation', 'Capitals' , 'Words']]\n",
    "#y_test = test[['Spam']]\n",
    "\n",
    "\n",
    "#if not (path.exists(\"../data/spam/model2\")):\n",
    "#    model = make_model(input_dims=4)\n",
    "#    model.fit(x_train, y_train, epochs=10, batch_size=10)\n",
    "#    model.evaluate(x_test, y_test)\n",
    "#    model.save('../data/spam/model2')\n",
    "#else:\n",
    "#    model = tf.keras.models.load_model('../data/spam/model2')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
